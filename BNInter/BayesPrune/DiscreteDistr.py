"""Classes for handling multivariate discrete distributions."""

import numpy as np
import Utils.SEtree
import Utils.Counts
import random

class DiscreteDistrSOP:
    """A multivariate discrete distribution represented as a sum of
    products.

    Supports fast generation of marginal distributions, through bucket
    elimination (through sop.py), marginalization, caching."""
    
    def __init__(self, sop):
        """Initialize the distribution from a SOP."""
        self.sop = sop
        self.cache = {} # cache for marginals
        self.cost_cache = {} # cache for costs of computing marginals


    def marginalize_subsets(self, vars, distr):
        """Marginalize distr over all direct subsets of vars, and
        insert marginal into the cache."""
        for i in range(len(vars)):
            subset = vars[0:i] + vars[i+1:]
            if subset not in self.cache:
                subdistr = np.array(np.sum(distr, i))
                self.cache[subset] = subdistr
        

    def get_marginal(self, vars):
        """Gets a marginal distribution over given variables."""
        vars = tuple(vars)
        if vars not in self.cache:
            self.sop.prepare(list(vars))
            distr = self.sop.compute()
            self.cache[vars] = distr
        else:
            distr = self.cache[vars]
        self.marginalize_subsets(vars, distr)
        # marginalize + insert subsets
        return distr

    def benefit(self, superset, setree):
        if tuple(superset) not in self.cost_cache:
            self.sop.prepare(superset)
            mem_cost = self.sop.mem_cost()
            res_size = self.sop.result_size()
            cost = self.sop.cost()
            self.cost_cache[tuple(superset)] = (cost, mem_cost, res_size)
        else:
            cost, mem_cost, res_size = self.cost_cache[tuple(superset)]
        # dont do too large attribute sets
        if mem_cost > 450000000: #0.5GB - skip completely
            return -1000
        if mem_cost > 50000000: # limit - don't create larger supersets
            return -10
        superset_res_size = res_size
        benefit  = -cost[0] - cost[1]
        hasSubsets = False
        for vars in setree.iter_included(tuple(superset)):
            hasSubsets = True
            # TODO: make BE cost cache aware
            if vars not in self.cost_cache:
                self.sop.prepare(vars)
                cost = self.sop.cost()
                mem_cost = self.sop.mem_cost()
                res_size = self.sop.result_size()
                self.cost_cache[vars] = (cost, mem_cost, res_size)
            else:
                cost, mem_cost, res_size = self.cost_cache[vars]
            benefit = benefit + cost[0] + cost[1]
            benefit -= (superset_res_size / res_size - 1) * res_size
        # if just the set itself is computed, benefit is 0
        # this is a hack to compensate for small negative return values
        if not hasSubsets:
            benefit = 0
        return benefit

    def find_best_superset(self, vars, setree):
        #find most desirable superset
        bestsuperset = list(vars)
        bestbenefit = self.benefit(vars, setree)
        nextiter = True
        superset = bestsuperset
        while nextiter and len(superset) < min(self.sop.n, 10): # TODO: remove fixed limit
            nextiter = False
            superset = bestsuperset
            #various strategies for adding attrs:
            #1. try all attrs
            #s = xrange(self.sop.n)
            #2. try a few random ones
            s = list(range(self.sop.n))
            random.shuffle(s)
            s = s[0:10]
            for v in s:
                if v in superset:
                    continue
                tmp = superset + [v]
                tmp.sort()
                benefit = self.benefit(tmp, setree)
                #print superset, tmp, benefit
                if benefit > bestbenefit:
                    bestbenefit = benefit
                    bestsuperset = tmp
                    nextiter = True
        print(bestsuperset, bestbenefit, vars)
        if bestbenefit <= -1000:
            print(list(vars), " out of memory")
        return bestsuperset, bestbenefit

    def get_positive_border_marginals(self, border):
        """Gets a marginal for each variable set in a positive border
        of a family of attribute sets generated by Apriori."""


        border2 = [x for x in border if x not in self.cache]
        print( (len(border) - len(border2)), "sets skipped: already in cache")
        border = border2
        
        ntogo = len(border)
        ntotal = ntogo
        setree = Utils.SEtree.SEtree()
        for vars in border:
            setree[vars] = None
            
        for vars in border:
            if vars in self.cache:
                continue
            bestsuperset, bestbenefit = self.find_best_superset(vars, setree)

            #marginalize marginals included in bestsuperset
            if bestbenefit > -1000:
                self.sop.prepare(bestsuperset)
                superdistr = self.sop.compute()
            vars_to_remove = []
            for vars in setree.iter_included(bestsuperset):
                if bestbenefit > -1000:
                    distr = Utils.Counts.marginalize_numpy(superdistr, bestsuperset, vars)
                    self.cache[vars] = distr
                vars_to_remove.append(vars)
            for vars in vars_to_remove:
                del setree[vars]
            ntogo -= len(vars_to_remove)
            print(ntogo, " variable sets to go out of", ntotal)

